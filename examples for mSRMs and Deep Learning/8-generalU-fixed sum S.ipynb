{"cells":[{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3775,"status":"ok","timestamp":1671476346739,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"uGVkY0iudlmi","outputId":"f09bc75f-8294-46c5-f375-b8f8cde7ab38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Correlation:\n"," [[1.         0.69636521 0.53737256 0.44310949 0.80040848 0.88379991\n","  0.57058305 0.54899297 0.782578  ]\n"," [0.69636521 1.         0.69206624 0.70880887 0.71866878 0.77061824\n","  0.79093166 0.70271291 0.90109849]\n"," [0.53737256 0.69206624 1.         0.84754383 0.71853314 0.62123292\n","  0.6631882  0.93876966 0.68595406]\n"," [0.44310949 0.70880887 0.84754383 1.         0.63848428 0.50482984\n","  0.84066672 0.88948408 0.75302503]\n"," [0.80040848 0.71866878 0.71853314 0.63848428 1.         0.68018215\n","  0.70474708 0.81922751 0.7684883 ]\n"," [0.88379991 0.77061824 0.62123292 0.50482984 0.68018215 1.\n","  0.47049513 0.53617135 0.77089533]\n"," [0.57058305 0.79093166 0.6631882  0.84066672 0.70474708 0.47049513\n","  1.         0.80795573 0.76914079]\n"," [0.54899297 0.70271291 0.93876966 0.88948408 0.81922751 0.53617135\n","  0.80795573 1.         0.70538967]\n"," [0.782578   0.90109849 0.68595406 0.75302503 0.7684883  0.77089533\n","  0.76914079 0.70538967 1.        ]] \n"," and Standard deviation:  [0.02834747652200631, 0.8357651039198697, 0.43276706790505337, 0.762280082457942, 0.0021060533511106927, 0.4453871940548014, 0.7215400323407826, 0.22876222127045265, 0.9452706955539223]\n"]}],"source":["'''\n","assume GENERAL exponential utility and Gaussian distribution for N-1 dim, here is a simplfied neural network to learn the overall risk and fair measure transformation\n","based on primal and dual problem\n","'''\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import random\n","from scipy.stats import multivariate_normal\n","import pandas as df\n","import random\n","import matplotlib.pyplot as plt\n","import time\n","\n","np.random.seed(1)\n","random.seed(1)\n","\n","# Define a class Gaussian Distribution to Generate the Gaussion Distribution in N-1, -dimensions\n","class GaussianND:\n","    # initialize the class\n","    def __init__(self,n_samples,n_institutions,means,covariance,fixed_s):\n","        '''\n","        Input:  n_institutions: number N\n","              means: list 1 x N\n","              covariance: 2D array: N x N\n","        Output: Generate function: n_samples x N \n","        '''\n","        # Initialize the parameters\n","        self.n_samples = n_samples\n","        self.N = n_institutions\n","        self.means = means\n","        self.covariance = covariance\n","        # Get the eigen value and eigen vectors, to help generate N-dimensional data\n","        self.eigen_values, self.eigen_vectors = np.linalg.eig(self.covariance)\n","        self.s = fixed_s\n","    def generate(self):\n","        component = []\n","        for i in range(self.n_samples):\n","            z = np.random.normal(0,1,self.N)\n","            x = self.means\n","            #print(x,\"\\n\",self.covariance,\"\\n\",self.eigen_values, \"\\n\",self.eigen_vectors)\n","            for j in range(self.N):\n","              x += np.sqrt(self.eigen_values[j])*z[j]*self.eigen_vectors[j]\n","            x = np.append(x,self.s-np.sum(x))\n","            component.append(x)\n","        return component\n","\n","def generate_sample(n_samples,n_institutions,means,covariance,fixed_s):\n","    '''\n","    return np.array: n_samples x n_institutions\n","    '''\n","    sample = GaussianND(n_samples,n_institutions,means,covariance,fixed_s).generate()\n","    #print(sample[0:3])\n","    #data = df.DataFrame(np.array(sample))#columns= ['Inst 1','Inst 2','Inst 3']\n","    return np.array(sample)\n","\n","#generate a random positive semi-definite N*N integer matrix as integer covariace matrix, in [0,m]\n","def generate_covint(N,m):\n","    A = np.random.rand(N,N)*m\n","    D = np.dot(A,A.transpose())\n","    return D\n","#convert covariance to correlation matrix and sigma vector: cor = diag^{-1}*cov*diag^{-1}\n","def func_correlation(cov, N):\n","    diag = np.zeros((N,N))      #diagonal matrix\n","    sig = []\n","    for i in range(N):\n","        diag[i][i] = cov[i][i]\n","        sig.append(np.sqrt(cov[i][i]))\n","    inv_diag_sqrt = np.linalg.inv(np.sqrt(diag))\n","    #print(\"covariance\\n\", cov,\"\\ndiagnal matrix\\n\",diag,\"\\ninverse diag suare root(sigma)\\n\", inv_diag_sqrt)\n","    return (np.dot(np.dot(inv_diag_sqrt,cov),inv_diag_sqrt)), sig\n","\n","\n","# number of sample \n","number_of_sample = 50000\n","number_of_test = 10000\n","n_institutions = 9\n","fixed_s = 15\n","\n","\n","\n","#means = [0]*n_institutions\n","means = sorted([(random.random()*3+0.1) for i in range(n_institutions)]) #[5]*n_institutions\n","\n","\n","### control sigma < mean\n","covariance = generate_covint(n_institutions,1)\n","cor_mat = func_correlation(covariance, n_institutions)[0]\n","#sig = [random.uniform(0,min(means[i],10)) for i in range(n_institutions)]\n","sig = [random.uniform(0,1) for i in range(n_institutions)]\n","covariance = np.dot(np.dot(np.diag(sig),cor_mat),np.diag(sig))\n","print(\"Correlation:\\n\",cor_mat,\"\\n and Standard deviation: \",sig )\n","###\n","\n","\n","train_data = generate_sample(number_of_sample,n_institutions,means,covariance,fixed_s)\n","##val_data = generate_sample(number_of_val,n_institutions,means,covariance)\n","test_data = generate_sample(number_of_test,n_institutions,means,covariance,fixed_s)\n","\n","n_institutions = 10"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671476450792,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"NFC5FRF998xK","outputId":"3dc8e04e-ec22-476e-ea11-dcfc1f80b273"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.38157876032270466,\n"," 0.5030927323372036,\n"," 0.8652070772182651,\n"," 1.4484731943662146,\n"," 1.586305261275823,\n"," 2.0547789181682887,\n"," 2.391323856929842,\n"," 2.4661700534065396,\n"," 2.642301210811698]"]},"metadata":{},"execution_count":28}],"source":["means# for first 9"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"DOuYA6dGGHc4","executionInfo":{"status":"ok","timestamp":1671476476909,"user_tz":480,"elapsed":7892,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"}}},"outputs":[],"source":["import torch\n","#import torchvision\n","#import torchvision.transforms as transforms\n","#import matplotlib.pyplot as plt\n","#import random\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","## Training on GPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","'''if device.type == 'cuda':\n","    print(torch.cuda.get_device_name(0))\n","    print('Memory Usage:')\n","    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n","    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n","'''\n","\n","batch_size=1000\n","## Tensor Initialization\n","data_=torch.from_numpy(train_data).to(device)\n","dataset = torch.utils.data.TensorDataset(data_)\n","trainloader = torch.utils.data.DataLoader(dataset,batch_size, shuffle = False)\n","# validation data\n","##validation_data=torch.from_numpy(val_data).to(device)\n","# testing data\n","testdata=torch.from_numpy(test_data).to(device)\n","dataset = torch.utils.data.TensorDataset(testdata)\n","testloader = torch.utils.data.DataLoader(dataset,batch_size, shuffle = False)"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671476476910,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"cHneQeb87d4C","outputId":"59ef16a1-54ed-4617-9885-632f51d5338f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":30}],"source":["device"]},{"cell_type":"markdown","metadata":{"id":"UCoryR7bcrhZ"},"source":["# Dual first"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"meU5aICr35zG","executionInfo":{"status":"ok","timestamp":1671476482228,"user_tz":480,"elapsed":357,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"}}},"outputs":[],"source":["\n","# NN: Generator, return -alpha_B\n","class Generator(nn.Module):\n","    def __init__(self,input_dim,hidden_dim,output_dim):\n","        '''\n","        input_dim: number of uniform rvs, i.e. n_institutions \n","        hidden_dim: list of hidden layer dimensions\n","        output_dim: number of classes i.e. n_institutions \n","        '''\n","        super(Generator, self).__init__()\n","        model = [nn.Linear(input_dim, hidden_dim[0])]\n","        for i in range(len(hidden_dim)-1):\n","          model.append(nn.Linear(hidden_dim[i], hidden_dim[i+1]))\n","        model.append(nn.Linear(hidden_dim[-1], output_dim))\n","        self.model = nn.ModuleList(model)   \n","        \n","\n","    def forward(self, x):\n","        '''\n","        Use ReLU nonlinearities in the layers, and nothing at the output.\n","        '''\n","        for i in range(len(self.model)-1):\n","          x = torch.relu(self.model[i](x))\n","        #x=torch.sigmoid(self.model[-1](x))\n","        #x=F.elu(self.model[-1](x))\n","        x=self.model[-1](x)\n","        return x\n","\n","class Alpha_Loss(nn.Module):\n","    def __init__(self,utility,u_parameters, B, lam):\n","        \"\"\"\n","        input:\n","            dQ_dP: current tranformation, siz M x 1\n","            utility function: 'exp','...'\n","            parameter for utitlity function: list of u_paramaters\n","        \"\"\"\n","        super(Alpha_Loss, self).__init__()\n","        self.u = utility\n","        self.u_parameters = torch.tensor(u_parameters,device = 'cuda:0')\n","        self.B, self.lam = B, lam\n","        \n","    def calculate_u(self, z):\n","        '''\n","        input:\n","          z - tensor(batch, N)\n","        return:\n","          tensor(batch), utilitiess of Z across N\n","        '''\n","        if self.u == 'exp':\n","          return torch.sum(-torch.exp(-z*self.u_parameters)/self.u_parameters, dim=1)\n","        if self.u == 'exp_pairsum':\n","          return n_institutions**2/2-torch.square(torch.sum(torch.exp(-z*self.u_parameters), dim=1))/2\n","          #return torch.sub(-torch.square(torch.sum(torch.exp(-z*self.u_parameters), dim=1))/2, -n_institutions**2/2)\n","        \n","    def forward(self, dQ_dP, Z):\n","        \"\"\"\n","        input:\n","            Z -- inputs: M x N\n","        return: value of loss function\n","        \"\"\"\n","        # control lost\n","        sum_trans_Z = torch.reshape(torch.sum(Z, 1),(-1,1))*dQ_dP\n","        sum_u = self.calculate_u(Z)\n","        \n","        self.term1 = self.B - torch.mean(sum_u)\n","        self.term2 = torch.mean(sum_trans_Z)\n","        return torch.mean(sum_trans_Z)  + self.lam*torch.relu(self.B - torch.mean(sum_u))\n","    def print_loss(self):\n","        print(\"B-E U\",self.term1.item())\n","        print(\"-alpha\",self.term2.item())\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"KouMhCy6F9wJ","executionInfo":{"status":"ok","timestamp":1671476483564,"user_tz":480,"elapsed":6,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"}}},"outputs":[],"source":["# Neural Networks: approximate rho\n","class Net(nn.Module):\n","    def __init__(self,input_dim,hidden_dim,output_dim):\n","        '''\n","        uniform tranformation for X_i, thus input 1-d and output 1-d\n","          input_dim: N\n","          hidden_dim: list of hidden layer dimensions\n","          output_dim: 1\n","        '''\n","        super(Net, self).__init__()\n","        # an affine operation: y = Wx + b\n","        model = [nn.Linear(input_dim, hidden_dim[0])]\n","        for i in range(len(hidden_dim)-1):\n","          model.append(nn.Linear(hidden_dim[i], hidden_dim[i+1]))\n","        model.append(nn.Linear(hidden_dim[-1], output_dim))\n","        self.model = nn.ModuleList(model)   \n","        \n","\n","    def forward(self, x):\n","        '''\n","        Use ReLU nonlinearities in the layers, and relu at the output.\n","        '''\n","        for i in range(len(self.model)-1):\n","          x = torch.relu(self.model[i](x))\n","        #x=torch.sigmoid(self.model[-1](x))\n","        #x=F.elu(self.model[-1](x))\n","        #x=self.model[-1](x)\n","        x = torch.log(1 + torch.exp(self.model[-1](x)))# torch.relu(self.model[-1](x))+0.01\n","        return x/torch.mean(x)\n","\n","class Loss(nn.Module):\n","    def __init__(self, u_paramaters, B):\n","        super(Loss, self).__init__()\n","        self.alphas = torch.tensor(u_paramaters).to(device)\n","        self.B = B\n","        self.beta = self.calculate_par()\n","\n","    def calculate_par(self):\n","        beta = 0\n","        for alpha in self.alphas:\n","          beta += 1/alpha\n","        return beta\n","        \n","    def forward(self,data,dQ_dP,loss_alpha):\n","        \"\"\"\n","        input:\n","            dQ_dP -- inputs: M x 1, generated from X by NN\n","            loss_alpha -- minimized 1 x 1 tensor under current dQ_dP, i.e. -alpha\n","        return: value of loss function\n","        \"\"\"\n","        # control lost\n","        sum_X = torch.reshape(torch.sum(data, 1),(-1,1))\n","        \n","        return torch.mean(sum_X*dQ_dP, 0)  - loss_alpha"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"LxwbS6qnvlD6","executionInfo":{"status":"ok","timestamp":1671476487200,"user_tz":480,"elapsed":568,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"}}},"outputs":[],"source":["#u_parameters = sorted([random.uniform(0.8, 2) for i in range(n_institutions)]) #[1,2,3]\n","\n","u_parameters  = [1.1122798436470818,#0.8676421969658913,\n","  1.2,\n"," 1.3600655431719748,\n"," 1.8948894071014162,\n"," 1.942496453417903,\n"," 2.0424170726028246,\n"," 2.26928838290612,\n"," 2.3344025824476655,\n"," 2.6278998816486365,\n"," 2.9867918993531175]\n","\n","a =[round(num,3) for num in u_parameters]\n"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"5BtVhBa3gyuS","executionInfo":{"status":"ok","timestamp":1671476489602,"user_tz":480,"elapsed":4,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"}}},"outputs":[],"source":["utility, B, lam_alpha  = 'exp_pairsum',-1,0.1 #10 #'exp'，'exp_pairsum'\n","\n","input_dim= n_institutions     # how many Variables are in the dataset\n","hidden_dim = [64,64]#[64,32]          # hidden layer dimensions\n","#output_dim= n_institutions   # number of classes\n","\n","\n","## Instantiating the transformer\n","net = Net(input_dim,hidden_dim ,1).to(device)\n","criterion = Loss(u_parameters,B)\n","learning_rate = 0.001#0.001\n","optimizer = optim.SGD(net.parameters(), lr=learning_rate,weight_decay=0.0001)\n","\n","generator = Generator(n_institutions,[64,64],n_institutions).to(device)\n","gen_criterion = Alpha_Loss(utility,u_parameters, B, lam_alpha)\n","gen_optimizer = optim.SGD(generator.parameters(), lr=0.001, weight_decay=0.0001)#0.0005\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":316,"status":"ok","timestamp":1671476493679,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"qq62zn_C7WzJ","outputId":"732b79be-773c-4228-b62c-cadfacd42f08"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":35}],"source":["device"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325213,"status":"ok","timestamp":1671476835904,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"K3wYxDZvyyIb","outputId":"9ce8e39a-5342-4601-f176-0eb7518aaa1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Net 1\n","Epoch 50/1000\n","B-E U 0.640810489654541\n","-alpha -0.3800722062587738\n","Learn -rho, Training Loss: 15.323\n","Epoch 100/1000\n","B-E U -0.2812299132347107\n","-alpha -0.3307647705078125\n","Learn -rho, Training Loss: 15.332\n","Epoch 150/1000\n","B-E U 0.11312258243560791\n","-alpha -0.35285383462905884\n","Learn -rho, Training Loss: 15.335\n","Epoch 200/1000\n","B-E U -0.16720789670944214\n","-alpha -0.3377952575683594\n","Learn -rho, Training Loss: 15.342\n","Epoch 250/1000\n","B-E U 0.05457186698913574\n","-alpha -0.3500732183456421\n","Learn -rho, Training Loss: 15.342\n","Epoch 300/1000\n","B-E U -0.05456435680389404\n","-alpha -0.344195157289505\n","Learn -rho, Training Loss: 15.343\n","Epoch 350/1000\n","B-E U -0.11277902126312256\n","-alpha -0.3410801887512207\n","Learn -rho, Training Loss: 15.343\n","Epoch 400/1000\n","B-E U -0.06474649906158447\n","-alpha -0.3437769412994385\n","Learn -rho, Training Loss: 15.345\n","Epoch 450/1000\n","B-E U 0.048932790756225586\n","-alpha -0.35003113746643066\n","Learn -rho, Training Loss: 15.345\n","Epoch 500/1000\n","B-E U 0.018210649490356445\n","-alpha -0.3483750820159912\n","Learn -rho, Training Loss: 15.345\n","Epoch 550/1000\n","B-E U -0.013145208358764648\n","-alpha -0.3466823995113373\n","Learn -rho, Training Loss: 15.345\n","Epoch 600/1000\n","B-E U -0.027508020401000977\n","-alpha -0.34591639041900635\n","Learn -rho, Training Loss: 15.346\n","Epoch 650/1000\n","B-E U 0.0276566743850708\n","-alpha -0.34894707798957825\n","Learn -rho, Training Loss: 15.346\n","Epoch 700/1000\n","B-E U 0.0012764930725097656\n","-alpha -0.347513347864151\n","Learn -rho, Training Loss: 15.346\n","Epoch 750/1000\n","B-E U -0.02607637643814087\n","-alpha -0.34602516889572144\n","Learn -rho, Training Loss: 15.346\n","Epoch 800/1000\n","B-E U -0.004212498664855957\n","-alpha -0.3472316563129425\n","Learn -rho, Training Loss: 15.347\n","Epoch 850/1000\n","B-E U -0.0010242462158203125\n","-alpha -0.3474108576774597\n","Learn -rho, Training Loss: 15.347\n","Epoch 900/1000\n","B-E U 0.002396106719970703\n","-alpha -0.3476026654243469\n","Learn -rho, Training Loss: 15.347\n","Epoch 950/1000\n","B-E U 0.006412148475646973\n","-alpha -0.3478269875049591\n","Learn -rho, Training Loss: 15.347\n","Epoch 1000/1000\n","B-E U 0.009878277778625488\n","-alpha -0.3480210304260254\n","Learn -rho, Training Loss: 15.347\n","B-E U 0.009878277778625488\n","-alpha -0.3480210304260254\n","Finished Training for Net  1\n","training time is 5.42 minutes\n"]}],"source":["## 3. Training the neural network model\n","num_epochs = 1000#4000#2000\n","\n","l_set = []\n","for j in range(1):\n","  print(\"Net {}\".format(j+1))\n","  error_rate_paths=[[],[]]\n","  start_time = time.time()\n","  for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      if (epoch+1) % 200 == 0 and epoch+1<num_epochs:\n","        optimizer.param_groups[0]['lr'] /= 2\n","        gen_optimizer.param_groups[0]['lr'] /= 2\n","        #gen_criterion.lam *=2 #5\n","\n","        \n","\n","      print_bool = False\n","      if (epoch+1) % 50 ==0: \n","        print_bool = True\n","        print(\"Epoch {}/{}\".format(epoch+1,num_epochs))\n","\n","      running_loss = 0.0\n","      dQ_dP = torch.tensor([])\n","      for i, data in enumerate(trainloader, 0):\n","          # get the inputs; data is a list of [N-dim inputs]\n","          input = data[0]\n","          # zero the parameter gradients, before each instance\n","          optimizer.zero_grad()\n","          # forward + backward + optimize\n","          output = net(input.float())   #dQ/dP , 500 x 1\n","\n","          gen_optimizer.zero_grad()\n","          Z = generator(input.float())\n","          loss_alpha = gen_criterion(output,Z)\n","\n","          loss = criterion(input,output,loss_alpha)\n","          loss.backward()\n","\n","          for par in generator.parameters():\n","            par.grad *= -1\n","          gen_optimizer.step()\n","          optimizer.step()    # Does the update\n","          \n","\n","          # print statistics\n","          running_loss += loss.item()\n","      l_set.append(running_loss / (i+1))\n","      if print_bool:\n","        gen_criterion.print_loss()\n","        ##print('loss function of alpha:',loss_alpha)\n","        print(\"Learn -rho, Training Loss: {:.3f}\".format(running_loss / (i+1)))\n","  end_time = time.time()\n","  gen_criterion.print_loss()\n","  print('Finished Training for Net ',j+1)\n","  print(f\"training time is {(end_time-start_time)/60:.2f} minutes\")\n"," "]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671476844227,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"r6VopiEtMvSt","outputId":"3cc95a85-6b55-404f-b2ef-19f77acc452a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["\n","plt.plot(np.arange(num_epochs),l_set)# s = 0.1\n","#plt.ylim((52,53))\n","plt.xlabel('number of epochs')\n","plt.ylabel('loss')\n","plt.show() "]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1437,"status":"ok","timestamp":1671476499742,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"70MQVUXfw32h","outputId":"86e95362-690d-4119-ebf9-c92c1ea5e9da"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-36-14a0bb6ae8f1>:80: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  EQ_Yk = torch.tensor(EQ_Yk, requires_grad=True).to(self.Y.device)\n"]}],"source":["class ExpExample:\n","  def __init__(self,data,u_parameters, B):\n","    '''\n","    data: sample size M x N\n","    u_parameters: list, alpha's of exponential utility\n","    B: number\n","    Notes:  calculate explicit result presented in Thm 6.2, wich group size h=1\n","            \"expentation\" is calculated by sample, not MGF of X\n","    '''\n","    self.X = data\n","    self.alphas = u_parameters\n","    self.B = B\n","    self.beta, self.inv_alpha, self.gam, self.inv_gam = self.calculate_par()   # inv_alpha is a tensor\n","    self.M = self.X.size(dim=0)\n","    self.N = self.X.size(dim=1)\n","    self.sum_X = torch.sum(self.X, 1)\n","    self.d,self.exp_X, self.mean_exp_X = self.calculate_d()\n","    self.Y = self.calculate_Yk()\n","    self.EQ_Y = self.EQ_Y()\n","    self.QP = self.Q()\n","    self.rho = self.d-self.gam\n","\n","\n","  def calculate_par(self):\n","    beta = 0\n","    inv_alpha = []\n","    inv_gam = []\n","    gam = 0\n","    for alpha in self.alphas:\n","      beta += 1/alpha\n","      gam += 1/alpha*np.log(1/alpha)\n","      inv_gam.append(1/alpha*np.log(1/alpha))\n","      inv_alpha.append(1/alpha)\n","    inv_alpha = torch.tensor(inv_alpha, requires_grad=True).to(self.X.device)\n","    inv_gam = torch.tensor(inv_gam, requires_grad=True).to(self.X.device)\n","    return beta,inv_alpha, gam, inv_gam\n","\n","\n","  def calculate_d(self):\n","    exp_X = []\n","    for i in range(self.M):\n","      exp_X.append(torch.exp(-2*self.sum_X[i]/self.beta))\n","    exp_X=torch.tensor(exp_X, requires_grad=True).to(self.X.device)\n","    emp_mgf = torch.mean(exp_X)\n","    d = self.beta/2 * torch.log(self.beta**2/(n_institutions **2 - 2*self.B) * emp_mgf)\n","    return d,exp_X,emp_mgf\n","\n","  def calculate_Yk(self):\n","    '''\n","    return: Y of size (M,N)\n","    '''\n","    Y = -self.X\n","    for i in range(self.M):\n","      # calculate every vector Y = (Y^1,...Y^N) line by line: Y = -X + 1/beta * (X_bar+d) * ALPHA(1,N)\n","      #print(self.sum_X[i].size,self.d,\"\\n\",torch.add(self.sum_X[i],self.d),\"\\n times vector\",torch.mul(self.d,self.inv_alpha))\n","      Y[i] += (1/self.beta *torch.add(self.sum_X[i],self.d) * self.inv_alpha- self.inv_gam)\n","    return Y\n","  \n","  def calculate_Eu(self):\n","    '''\n","    return: U(X^n+Y^n)\n","    '''\n","    sum_u = []\n","    for j in range(self.M):\n","      sum = 0\n","      for i in range(self.N):\n","        sum += -torch.exp(-self.alphas[i]* (self.X[j][i]+self.Y[j][i]))/self.alphas[i]\n","      sum_u.append(sum)\n","    sum_u=torch.tensor(sum_u, requires_grad=True).to(self.X.device)\n","    return torch.mean(sum_u)\n","\n","  def EQ_Y(self):\n","    '''\n","    return: fair risk allocations E_{Q}[Y^n]\n","    '''\n","    trans_Yk = self.Y\n","    for i in range(self.M):\n","      trans_Yk[i] *= self.exp_X[i]/self.mean_exp_X\n","    EQ_Yk = torch.mean(trans_Yk,dim = 0)  #mean for each column i.e. n\n","    EQ_Yk = torch.tensor(EQ_Yk, requires_grad=True).to(self.Y.device)\n","    return EQ_Yk\n","\n","  def Q(self):\n","    '''\n","    return: fair measure density dQ/dP\n","    '''\n","    return (self.exp_X/self.mean_exp_X).to(self.Y.device)\n","\n","Example = ExpExample(testdata,u_parameters, B)#.to(device)\n"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333,"status":"ok","timestamp":1671476502528,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"OeGkZeasVN5Z","outputId":"d77d8cc6-4811-4ee1-aa00-a3c214fb9fc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overall risk/d/optimal of sum Y tensor(-15.3481, device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n","rho is tensor(-15.3481, device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)\n"]}],"source":["print(\"Overall risk/d/optimal of sum Y\", torch.mean(torch.sum(Example.Y,1)))\n","print('rho is', Example.rho)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671476505406,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"hXBg0EJHC25l","outputId":"1a670219-2670-4f29-b952-de84fc1b3718"},"outputs":[{"output_type":"stream","name":"stdout","text":["Individual risk/d/optimal Y^k tensor([-0.8187, -0.8442, -1.0771, -1.4229, -1.5482, -1.9907, -2.2934, -2.3643,\n","        -2.5001, -0.4885], device='cuda:0', dtype=torch.float64,\n","       grad_fn=<MeanBackward1>)\n"]}],"source":["print(\"Individual risk/d/optimal Y^k\", torch.mean(Example.Y,0))"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1671476852336,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"3K6kMUBDVRhZ","outputId":"86de0fee-1fd0-4592-f743-03095212945b"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 -0.34638601541519165\n","1 -0.3472079634666443\n","2 -0.3468417525291443\n","3 -0.34732988476753235\n","4 -0.3469654321670532\n","5 -0.34722253680229187\n","6 -0.34667345881462097\n","7 -0.3474437892436981\n","8 -0.3473479747772217\n","9 -0.3469405174255371\n","B-E U -0.009709060192108154\n","-alpha -0.3469405174255371\n","Testing loss: 15.347\n","From numerical, mean is  tensor(1.0000, device='cuda:0', grad_fn=<MeanBackward0>) optimal mean is tensor(1., device='cuda:0', dtype=torch.float64, grad_fn=<MeanBackward0>)\n"]}],"source":["\n","# Numerial: check accuracy of predicted fair individual allocation, with test data\n","\n","output = torch.tensor([]).to(device)\n","l_alpha = 0.0\n","l = 0.0\n","for i, data in enumerate(testloader, 0):\n","  testinput = data[0]\n","  testoutput = net(testinput.float())  \n","  testZ = generator(testinput.float())\n","  loss_alpha = gen_criterion(testoutput,testZ)\n","  loss = criterion(testinput,testoutput,loss_alpha)\n","  l_alpha += loss_alpha.item()\n","  print(i,loss_alpha.item())\n","  l += loss.item()\n","  output = torch.cat([output,testoutput])\n","gen_criterion.print_loss()\n","print(\"Testing loss: {:.3f}\".format(l / (i+1)))\n","\n","diff = output.view(-1) - Example.QP\n","\n","relative_error = torch.mean(diff**2)**0.5/ torch.mean(Example.QP**2)**0.5\n","print(\"From numerical, mean is \",torch.mean(output), 'optimal mean is',torch.mean(Example.QP) )\n","#print(f\"Relative L2 Error rate for over 50000 samples: {relative_error.item()*100:.2f}%.\")"]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1671476860027,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"n1nBoAuVhWVF","outputId":"fed6bea2-0875-48dc-c054-7806232558c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Estimated alpha: see above or 0.34703593254089354 \n","Theoritical alpha on formula:  tensor(0.3481, device='cuda:0', dtype=torch.float64, grad_fn=<SubBackward0>)\n"]}],"source":["# alpha =beta/2 * E[dQ_dP * ln(dQ_dP)]+gamma-beta/2*log(beta**2/(N^2-2B))\n","print('Estimated alpha: see above or', -l_alpha/(i+1), '\\nTheoritical alpha on formula: ',Example.beta/2*torch.mean(Example.QP*torch.log(Example.QP),0)+Example.gam - Example.beta/2*np.log(Example.beta**2/(n_institutions**2-2*B)))"]},{"cell_type":"markdown","metadata":{"id":"vFA3Zr_EXGSo"},"source":["Metric to evaluate $dQ/dP$"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":441},"executionInfo":{"elapsed":1069,"status":"ok","timestamp":1671476870471,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"HUtNa6UHXVYx","outputId":"de3d16c0-a98c-4191-9043-36ba135b9045"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 540x432 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["#===================================================#\n","# figure setup fonts and so on... \n","# the label and font size should be adjusted such that \n","# the figure fits well into ACM template\n","import matplotlib\n","matplotlib.rcParams['pdf.fonttype'] = 42\n","matplotlib.rcParams['ps.fonttype'] = 42\n","\n","plt.rc('xtick', labelsize=15)    # fontsize of the tick labels\n","plt.rc('ytick', labelsize=15)\n","plt.rc('legend', fontsize=22) \n","plt.rc('axes', labelsize=25)\n","plt.rcParams[\"figure.figsize\"] = (7.5, 6)\n","#===================================================#\n","\n","## Graph fitting\n","fig = plt.figure()\n","plt.scatter(torch.sum(testdata,1).detach().cpu().numpy(),output.detach().cpu().numpy(),s = 5,label = \"Estimated\", alpha = 0.7)\n","plt.scatter(torch.sum(testdata,1).detach().cpu().numpy(),Example.QP.detach().cpu().numpy(),s = 5, color=\"indianred\", label = \"Theoretical\")\n","#plt.scatter(torch.sum(testdata,1).detach().cpu().numpy(),np.log(output.detach().cpu().numpy()),s = 5,label = \"Estimated\", alpha = 0.7)\n","#plt.scatter(torch.sum(testdata,1).detach().cpu().numpy(),np.log(Example.QP.detach().cpu().numpy()),s = 5, color=\"indianred\", label = \"Theoretical\")\n","#plt.scatter(torch.sum(testdata,1).detach().cpu().numpy(),-(2+0.4)/(Example.beta)*torch.sum(testdata,1).detach().cpu().numpy()+3.5-np.log(Example.mean_exp_X.detach().cpu().numpy()),s = 5, color=\"black\", label = \"slope -2.4/beta\")\n","\n","\n","#plt.ylim(0,10)\n","plt.xlabel(\"S\")# = \\sum_{n=1}^N X^n\n","plt.ylabel(r\"$\\frac{dQ}{d\\mathbb{P}}$\")\n","#plt.legend()\n","lgnd = plt.legend(loc=\"upper right\", scatterpoints=1, fontsize=15)\n","lgnd.legendHandles[0]._sizes = [30]\n","lgnd.legendHandles[1]._sizes = [30]\n","plt.tight_layout()\n","fig.savefig(\"dQdP_vs_sumX.pdf\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1666902773542,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":420},"id":"WSuVsBCrUnj2","outputId":"3474af44-68c6-45ea-e7f9-2db0eeab083c"},"outputs":[{"name":"stdout","output_type":"stream","text":["KL divergence:  tensor(0.0690, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n","Jensen-Shannon divergence:  tensor(870.1619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"]}],"source":["## Relative Entropy\n","#def relative_entropy(QP_hat,QP):\n","#  relative_e = torch.sum(QP_hat * torch.log(QP_hat/QP))\n","#  return relative_e\n","#print(\"KL divergence: \",relative_entropy(output.view(-1),Example.QP)/number_of_test)\n","#mid_dist = (output.view(-1) + Example.QP)/2\n","#print(\"Jensen-Shannon divergence: \",relative_entropy(output.view(-1),mid_dist)/2+relative_entropy(mid_dist,Example.QP)/2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":104,"status":"ok","timestamp":1655662272600,"user":{"displayName":"Ming Min","userId":"11788995929382306658"},"user_tz":300},"id":"eskwyJRhYlpB","outputId":"dbed13e2-fe61-4f8c-8e73-c85fccc6c510"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wasserstein Distance:  0.034588065255513084\n"]}],"source":["## Wasserstein Distance:  the minimum amount of “work” required to transform one to another\n","#from scipy.stats import wasserstein_distance\n","#print(\"Wasserstein Distance: \",wasserstein_distance(output.view(-1).cpu().detach().numpy(),Example.QP.cpu().detach().numpy()))"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":591,"status":"ok","timestamp":1671477552671,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"0_riuF7CEqkG","outputId":"5822a0d9-93f7-4542-cf0d-0554f5ece3ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Relative L1 Error rate: 0.92%.\n"]}],"source":["## Another Relative L1\n","re_1 = torch.mean(torch.abs(diff))/ torch.mean(torch.abs((Example.QP))) # output.view(-1) +\n","print(f\"Relative L1 Error rate: {re_1.item()*100:.2f}%.\")"]},{"cell_type":"markdown","metadata":{"id":"ad-CICPBc1fr"},"source":["# Primal and Combined with dual"]},{"cell_type":"markdown","metadata":{"id":"rG_GJo0xvG5x"},"source":["**Compare $E_Q[Y^n]$**"]},{"cell_type":"code","execution_count":47,"metadata":{"id":"L1lFJQqahVUo","executionInfo":{"status":"ok","timestamp":1671477988406,"user_tz":480,"elapsed":7,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"}}},"outputs":[],"source":["## Copy from learning for risk measures.... train NN to get Y's\n","# Neural Networks\n","class Net_Y(nn.Module):\n","    def __init__(self,input_dim,hidden_dim,output_dim):\n","        '''\n","        input_dim: how many variables are in the dataset, i.e. n_institutions \n","        hidden_dim: list of hidden layer dimensions\n","        output_dim: number of classes i.e. n_institutions \n","        '''\n","        super(Net_Y, self).__init__()\n","        # an affine operation: y = Wx + b\n","        model = [nn.Linear(input_dim, hidden_dim[0])]\n","        for i in range(len(hidden_dim)-1):\n","          model.append(nn.Linear(hidden_dim[i], hidden_dim[i+1]))\n","        model.append(nn.Linear(hidden_dim[-1], output_dim))\n","        self.model = nn.ModuleList(model)   \n","        \n","\n","    def forward(self, x):\n","        '''\n","        Use ReLU nonlinearities in the layers, and nothing at the output.\n","        '''\n","        for i in range(len(self.model)-1):\n","          x = torch.relu(self.model[i](x))\n","        #x=torch.sigmoid(self.model[-1](x))\n","        #x=F.elu(self.model[-1](x))\n","        #x=F.leaky_relu(self.model[-1](x))\n","        #x=torch.exp(self.model[-1](x))\n","        x=self.model[-1](x)\n","        return x\n","\n","class Loss_Y(nn.Module):\n","    def __init__(self, utility,u_paramaters, B, lam, mu):\n","        \"\"\"\n","        input:\n","            utility function: 'exp','...'\n","            parameter for utitlity function: list of u_paramaters\n","        \"\"\"\n","        super(Loss_Y, self).__init__()\n","        self.u = utility\n","        self.u_parameters = torch.tensor(u_paramaters, device=\"cuda\")\n","        self.B, self.lam, self.mu  = B, lam, mu\n","        \n","    def calculate_u(self, x):\n","        if self.u == 'exp':\n","          return torch.sum(-torch.exp(-x*self.u_parameters)/self.u_parameters, dim=1)\n","        if self.u == 'exp_pairsum':\n","          return n_institutions**2/2-torch.square(torch.sum(torch.exp(-x*self.u_parameters), dim=1))/2\n","        \n","    def forward(self, X, Y):\n","        \"\"\"\n","        input:\n","            X -- inputs: M x N\n","            Y -- outputs: M x N\n","        return: value of loss function\n","        \"\"\"\n","        M = X.size(dim=0)\n","        # control lost\n","        sum_Y = torch.sum(Y, 1)\n","        sum_u = self.calculate_u(X+Y)\n","        \n","        self.term1 = self.B - torch.mean(sum_u)\n","        self.term2 = torch.var(sum_Y)\n","        self.term3 = torch.mean(sum_Y)\n","        self.term4 = torch.mean(sum_u)\n","        \n","        return torch.mean(sum_Y)  + self.mu*torch.std(sum_Y) + self.lam*torch.relu(self.B - torch.mean(sum_u))#**2\n","\n","\n","    def print_loss(self):\n","        print(\"B-sum u_n\",self.term1.item(),\"\\nU(Xn+Yn)\",self.term4.item(), \"\\nvar(sumY)\",self.term2.item(), \"\\nmean(sumY)\", self.term3.item())\n","\n","utility, B, lam, mu = 'exp_pairsum',B, .02, 1  ######1,5\n","\n","input_dim= n_institutions     # how many Variables are in the dataset\n","hidden_dim = [64,64]          # hidden layer dimensions\n","output_dim= n_institutions   # number of classes\n","\n","\n","## Instantiating the classifier\n","net_Y = Net_Y(input_dim,hidden_dim ,output_dim).to(device)\n","criterion_Y = Loss_Y(utility,u_parameters, B, lam, mu)\n","learning_rate = 0.00001#0.0001\n","optimizer = optim.SGD(net_Y.parameters(), lr=learning_rate, weight_decay=0.0001)\n"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":20790,"status":"error","timestamp":1671478009192,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"CHDccV4JopH-","outputId":"74a9da2a-e3de-47fb-9f0d-08f5a8ab2c11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Net 1\n","Epoch 1/3000, Training Loss(rho): nan\n","Epoch 51/3000, Training Loss(rho): nan\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-48-3a9572e55141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           \u001b[0;31m# get the inputs; data is a list of [N-dim inputs]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# It may be accessed twice, so we use a list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["## 3. Training the neural network model\n","num_epochs = 3000#1600#3000 # 800,200? 20%\n","\n","l_set = []\n","for j in range(1):\n","  print(\"Net {}\".format(j+1))\n","  error_rate_paths=[[],[]]\n","  start_time = time.time()\n","  for epoch in range(num_epochs):  # loop over the dataset multiple times\n","      if (epoch+1) % 1000 == 0 and epoch+1<num_epochs: # 1000\n","        optimizer.param_groups[0]['lr'] /= 1\n","        \n","        criterion_Y.lam *= 10\n","        criterion_Y.mu *= 10\n","        \n","\n","      running_loss = 0.0\n","      for i, data in enumerate(trainloader, 0):\n","          # get the inputs; data is a list of [N-dim inputs]\n","          input = data[0]\n","          # zero the parameter gradients, before each instance\n","          optimizer.zero_grad()\n","          # forward + backward + optimize\n","          output_tmp = net_Y(input.float())\n","\n","          loss = criterion_Y(input, output_tmp)\n","          #print('loss',loss,'\\n',criterion_Y.print_loss())\n","          #print(loss.item())\n","          loss.backward()\n","          optimizer.step()    # Does the update\n","\n","          # print statisticsç\n","          running_loss += loss.item()\n","      l_set.append(running_loss / (i+1))\n","      if epoch % 50 ==0:\n","        print(\"Epoch {}/{}, Training Loss(rho): {:.3f}\".format(epoch+1,num_epochs, running_loss / (i+1)))\n","  end_time = time.time()\n","  criterion_Y.print_loss()\n","  print('Finished Training for Net ',j+1)\n","\n","print(f\"training time is {(end_time-start_time)/60:.2f} minutes\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1671477977352,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"3zfmfpJddXcD"},"outputs":[],"source":["plt.plot(np.arange(num_epochs),l_set)# s = 0.1\n","#plt.ylim((52,53))\n","plt.xlabel('number of epochs')\n","plt.ylabel('loss during calculating Y^i')\n","plt.show() "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1671477977352,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"p3dOVn-eXcWx"},"outputs":[],"source":["Y_output = net_Y(testdata.float())\n","EQY_output = torch.mean(Y_output*output,0)\n","print('NN Y.    ',np.round(torch.mean(Y_output,0).cpu().detach().numpy(), 2))\n","print('optimal Y',np.round(torch.mean(Example.Y,0).cpu().detach().numpy(), 2))\n","print('NN EQY.    ',np.round(EQY_output.cpu().detach().numpy(), 2))\n","print('optimal EQY',np.round(Example.EQ_Y.cpu().detach().numpy(), 2))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1671477977352,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"C8sd-K1RvgGk"},"outputs":[],"source":["torch.sum(EQY_output)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1671477977353,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"noPo8LqBvQG4"},"outputs":[],"source":["(EQY_output-Example.EQ_Y).cpu().detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1671477977353,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"bVgbRNOZvSSc"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","diff_EXP = torch.abs((EQY_output-Example.EQ_Y))#/Example.EQ_Y\n","plt.scatter(np.arange(n_institutions),diff_EXP.cpu().detach().numpy(),s = 10, color=\"indianred\")\n","#plt.ylim((0, 0.1))\n","plt.xlabel('n')\n","plt.title(r'Scatterplot of diff between estimated $E_Q[Y^n]$ and real $E_Q[Y^n]$' )#relative \n","#plt.legend()\n","plt.show()\n","print(f\"Relative error of predicted fair risk allocation: {torch.mean(diff_EXP)*100:.3f}%.\")\n","#print(diff_EXP*Example.EQ_Y, Example.EQ_Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1671477977353,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":480},"id":"qJ8DmsIBwY1S"},"outputs":[],"source":["torch.mean(diff_EXP)/torch.mean(torch.abs(Example.EQ_Y))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqRKT-CMYo1E"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qNny9YNV2FdY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I0fbEA2I2Fgg"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H96_Epxh2FjQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eOA8MGtZ2FmQ"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RdIO3V7M2Fo2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7941,"status":"ok","timestamp":1665727178782,"user":{"displayName":"Yichen Feng","userId":"08923174760532446682"},"user_tz":420},"id":"aZAUxiuRVIxr","outputId":"1ab382d7-8f17-4c06-d879-a3d78f3a4c0f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]}],"source":["# wrong\n","class ExpExample:\n","  def __init__(self,data,u_parameters, A):\n","    '''\n","    data: sample size M x N\n","    u_parameters: list, alpha's of exponential utility\n","    B: number\n","    Notes:  calculate explicit result presented in Thm 6.2, wich group size h=1\n","            \"expentation\" is calculated by sample, not MGF of X\n","    '''\n","    self.X = data\n","    self.alphas = u_parameters\n","    self.A = A\n","    self.beta, self.inv_alpha, self.gam, self.inv_gam = self.calculate_par()   # inv_alpha, inv_gam is a tensor\n","    self.M = self.X.size(dim=0)\n","    self.N = self.X.size(dim=1)\n","    self.sum_X = torch.sum(self.X, 1)\n","    self.exp_X, self.mean_exp_X = self.calculate_XEX()\n","    self.d,self.lamb_hat = self.calculate_d_lambhat()\n","    self.Y = self.calculate_Yk()\n","    self.EQ_Y = self.EQ_Y()\n","    self.QP = self.Q()\n","    #self.EU = self.calculate_Eu()\n","\n","\n","  def calculate_par(self):\n","    beta = 0\n","    inv_alpha = []\n","    inv_gam = []\n","    gam = 0\n","    for alpha in self.alphas:\n","      beta += 1/alpha\n","      gam += 1/alpha*np.log(1/alpha)\n","      inv_gam.append(1/alpha*np.log(1/alpha))\n","      inv_alpha.append(1/alpha)\n","    inv_alpha = torch.tensor(inv_alpha, requires_grad=True).to(self.X.device)\n","    inv_gam = torch.tensor(inv_gam, requires_grad=True).to(self.X.device)\n","    return beta,inv_alpha, gam, inv_gam\n","\n","  def calculate_XEX(self):\n","    exp_X = []\n","    for i in range(self.M):\n","      exp_X.append(torch.exp(-2*self.sum_X[i]/self.beta))\n","    exp_X=torch.tensor(exp_X, requires_grad=True).to(self.X.device)\n","    emp_mgf = torch.mean(exp_X)\n","    \n","    return exp_X,emp_mgf\n","\n","  def calculate_d_lambhat(self):\n","    lamb_hat = torch.exp(-2/self.beta*(self.A+self.beta+self.gam-self.beta/2*np.log(self.beta)-self.beta/2*torch.log(self.mean_exp_X)))\n","    d = -self.beta + self.beta/2*np.log(self.beta)-self.beta/2*torch.log(lamb_hat)+self.beta/2 * torch.log(self.mean_exp_X)\n","    return d,lamb_hat\n","\n","  def calculate_Yk(self):\n","    '''\n","    return: Y of size (M,N)\n","    '''\n","    Y = -self.X\n","    for i in range(self.M):\n","      # calculate every vector Y = (Y^1,...Y^N) line by line: Y = -X + 1/beta * (X_bar+d) * inv_alpha(1,N)-inv_gam(1,N)\n","      #print(self.sum_X[i].size,self.d,\"\\n\",torch.add(self.sum_X[i],self.d),\"\\n times vector\",torch.mul(self.d,self.inv_alpha))\n","      Y[i] += (1/self.beta *torch.add(self.sum_X[i],self.d) * self.inv_alpha - self.inv_gam)\n","    return Y\n","  \n","  def calculate_Eu(self):\n","    '''\n","    return: U(X^n+Y^n)\n","    '''\n","    sum_u = []\n","    for j in range(self.M):\n","      sum = 0\n","      for i in range(self.N):\n","        sum += torch.exp(-self.alphas[i]* (self.X[j][i]+self.Y[j][i]))\n","      sum = n_institutions**2/2-sum**2/2\n","      #print(j,sum)\n","      sum_u.append(sum)\n","    sum_u=torch.tensor(sum_u, requires_grad=True).to(self.X.device)\n","    return torch.mean(sum_u)\n","\n","  def EQ_Y(self):\n","    '''\n","    return: fair risk allocations E_{Q}[Y^n]\n","    '''\n","    trans_Yk = self.Y\n","    for i in range(self.M):\n","      trans_Yk[i] *= self.exp_X[i]/self.mean_exp_X\n","    EQ_Yk = torch.mean(trans_Yk,dim = 0)  #mean for each column i.e. n\n","    EQ_Yk = torch.tensor(EQ_Yk, requires_grad=True).to(self.Y.device)\n","    return EQ_Yk\n","\n","  def Q(self):\n","    '''\n","    return: fair measure density dQ/dP\n","    '''\n","    return (self.exp_X/self.mean_exp_X).to(self.Y.device)\n","\n","Example = ExpExample(testdata,u_parameters, A = -running_loss / (i+1))#10.75)#.to(device)#running_loss / (i+1)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}